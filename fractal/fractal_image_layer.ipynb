{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Analiza czerniaka za pomocą fraktalnej sieci neuronowej",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": "import tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": "Zapisujemy konfigurację do zmiennych.",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": "IMAGE_SIZE = 224\nBATCH_SIZE = 32",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": "Definiujemy warstwę, która będzie tworzyła obraz z fraktalnych cech podanych jej obrazów.",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": "class Fractal2D(tf.keras.layers.Layer):\n    def __init__(self, kernel_size_range):\n        super(Fractal2D, self).__init__()\n        self.kernel_size_range = kernel_size_range\n\n    def call(self, image_batch):\n        for kernel_size in range(self.kernel_size_range[0], self.kernel_size_range[1] + 1, 2):\n            split_image_batch = tf.image.extract_patches(image_batch,\n                                     sizes=(1, kernel_size, kernel_size, 1),\n                                     strides=(1, 1, 1, 1),\n                                     rates=(1, 1, 1, 1),\n                                     padding='SAME')\n            batch_size, row_size, col_size, depth = split_image_batch.shape\n            split_image_batch = tf.reshape(split_image_batch, shape=(batch_size, row_size * col_size, kernel_size, kernel_size, 3))\n            print(f'kernel_size: {kernel_size} -- shape: {split_image_batch.shape}')\n        return image_batch",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": "Ładujemy dane do trenowania i walidacji.",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 640 images belonging to 3 classes.\n",
      "Found 159 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": "datagen = ImageDataGenerator(validation_split=0.2)\ntraining_set = datagen.flow_from_directory('/small-data',\n                                           target_size=(IMAGE_SIZE, IMAGE_SIZE),\n                                           batch_size=BATCH_SIZE,\n                                           class_mode='categorical',\n                                           subset='training')\nvalidation_set = datagen.flow_from_directory('/small-data',\n                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n                                             batch_size=BATCH_SIZE,\n                                             class_mode='categorical',\n                                             subset='validation')",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": "Zapisujemy ilość rozpoznawalnych diagnoz.",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": "DIAGNOSIS_NUMBER = len(training_set.class_indices)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": "Tworzymy model, który wykorzystuje wcześniej zdefiniowaną warstwę.",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": "model = tf.keras.Sequential([\n    Fractal2D(kernel_size_range=(3, 41)),\n    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", output_shape=[1280],\n                   trainable=False),\n    tf.keras.layers.Dense(DIAGNOSIS_NUMBER, activation='softmax')\n])",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_size: 3 -- shape: (32, 50176, 3, 3, 3)\n",
      "kernel_size: 5 -- shape: (32, 50176, 5, 5, 3)\n",
      "kernel_size: 7 -- shape: (32, 50176, 7, 7, 3)\n",
      "kernel_size: 9 -- shape: (32, 50176, 9, 9, 3)\n",
      "kernel_size: 11 -- shape: (32, 50176, 11, 11, 3)\n",
      "kernel_size: 13 -- shape: (32, 50176, 13, 13, 3)\n",
      "kernel_size: 15 -- shape: (32, 50176, 15, 15, 3)\n",
      "kernel_size: 17 -- shape: (32, 50176, 17, 17, 3)\n",
      "kernel_size: 19 -- shape: (32, 50176, 19, 19, 3)\n",
      "kernel_size: 21 -- shape: (32, 50176, 21, 21, 3)\n",
      "kernel_size: 23 -- shape: (32, 50176, 23, 23, 3)\n",
      "kernel_size: 25 -- shape: (32, 50176, 25, 25, 3)\n",
      "kernel_size: 27 -- shape: (32, 50176, 27, 27, 3)\n",
      "kernel_size: 29 -- shape: (32, 50176, 29, 29, 3)\n",
      "kernel_size: 31 -- shape: (32, 50176, 31, 31, 3)\n",
      "kernel_size: 33 -- shape: (32, 50176, 33, 33, 3)\n",
      "kernel_size: 35 -- shape: (32, 50176, 35, 35, 3)\n",
      "kernel_size: 37 -- shape: (32, 50176, 37, 37, 3)\n",
      "kernel_size: 39 -- shape: (32, 50176, 39, 39, 3)\n",
      "kernel_size: 41 -- shape: (32, 50176, 41, 41, 3)\n",
      "kernel_size: 3 -- shape: (32, 50176, 3, 3, 3)\n",
      "kernel_size: 5 -- shape: (32, 50176, 5, 5, 3)\n",
      "kernel_size: 7 -- shape: (32, 50176, 7, 7, 3)\n",
      "kernel_size: 9 -- shape: (32, 50176, 9, 9, 3)\n"
     ]
    }
   ],
   "source": "model.fit(training_set, validation_data=validation_set, epochs=20)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "trusted": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}