{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Analiza czerniaka za pomocą fraktalnej sieci neuronowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import measurements\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzamy dostępne urządzenie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Zapisujemy konfigurację do zmiennych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definiujemy warstwę, która będzie tworzyła obraz z fraktalnych cech podanych jej obrazów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Fractal2D(tf.keras.layers.Layer):\n",
    "    PERCOLATION_THRESHOLD = 0.59275\n",
    "    \n",
    "    def __init__(self, kernel_size_range):\n",
    "        super(Fractal2D, self).__init__()\n",
    "        self.kernel_size_range = kernel_size_range\n",
    "\n",
    "    def chessboard_distance(self, patched_inputs, central_pixels, kernel_size):\n",
    "        return tf.cast(\n",
    "            tf.math.less_equal(\n",
    "                tf.math.reduce_max(\n",
    "                    tf.math.abs(tf.math.subtract(patched_inputs, central_pixels)), \n",
    "                    axis=3), \n",
    "                kernel_size), \n",
    "            dtype=tf.int32)\n",
    "    \n",
    "    def euclidean_distance(self, patched_inputs, central_pixels, kernel_size):\n",
    "        return tf.cast(\n",
    "            tf.math.less_equal(\n",
    "                tf.math.pow(\n",
    "                    tf.math.reduce_sum(\n",
    "                        tf.math.pow(\n",
    "                            tf.math.subtract(patched_inputs, central_pixels), \n",
    "                            2), \n",
    "                        axis=3), \n",
    "                    0.5), \n",
    "                kernel_size), \n",
    "            dtype=tf.int32)\n",
    "    \n",
    "    def manhattan_distance(self, patched_inputs, central_pixels, kernel_size):\n",
    "        return tf.cast(\n",
    "            tf.math.less_equal(\n",
    "                tf.math.reduce_sum(\n",
    "                    tf.math.abs(tf.math.subtract(patched_inputs, central_pixels)), \n",
    "                    axis=3), \n",
    "                kernel_size), \n",
    "            dtype=tf.int32)\n",
    "    \n",
    "    def extract_binary_patches(self, inputs, kernel_size, distance_function):\n",
    "        patched_inputs = tf.image.extract_patches(inputs,\n",
    "                                                     sizes=(1, kernel_size, kernel_size, 1),\n",
    "                                                     strides=(1, kernel_size, kernel_size, 1),\n",
    "                                                     rates=(1, 1, 1, 1),\n",
    "                                                     padding='SAME')\n",
    "        _, rows, cols, _ = patched_inputs.shape\n",
    "        patched_inputs = tf.reshape(patched_inputs, shape=(-1, kernel_size, kernel_size, 3))\n",
    "        \n",
    "        central_pixels = tf.image.resize_with_crop_or_pad(patched_inputs, 1, 1)\n",
    "        \n",
    "        return tf.reshape(distance_function(patched_inputs, central_pixels, kernel_size), shape=(-1, rows * cols, kernel_size, kernel_size))\n",
    "    \n",
    "    def calculate_probability_matrices(self, binary_inputs, kernel_size):\n",
    "        number_of_ones = tf.map_fn(lambda binary_input: tf.map_fn(lambda binary_patch: tf.math.reduce_sum(binary_patch), \n",
    "                                                                  binary_input), \n",
    "                                   binary_inputs)\n",
    "        _, patch_number = number_of_ones.shape\n",
    "        return tf.math.bincount(number_of_ones,\n",
    "                                minlength=1, \n",
    "                                maxlength=kernel_size ** 2 + 1, \n",
    "                                axis=-1) / patch_number\n",
    "    \n",
    "    def calculate_fractal_dimensions(self, probability_matrices):\n",
    "        def fd_helper(matrix):\n",
    "            return tf.math.reduce_sum(tf.math.divide(matrix, tf.range(1, len(matrix) + 1, dtype=tf.float64)))\n",
    "        return tf.map_fn(lambda matrix: fd_helper(matrix), probability_matrices)\n",
    "    \n",
    "    def calculate_lacunarity(self, probability_matrices):\n",
    "        def m_helper(matrix):\n",
    "            return tf.math.reduce_sum(tf.math.multiply(matrix, tf.range(1, len(matrix) + 1, dtype=tf.float64)))\n",
    "        \n",
    "        def m2_helper(matrix):\n",
    "            return tf.math.reduce_sum(tf.math.multiply(tf.math.pow(matrix, 2), tf.range(1, len(matrix) + 1, dtype=tf.float64)))\n",
    "        \n",
    "        return tf.map_fn(lambda probability_matrix: \n",
    "                         tf.math.divide(\n",
    "                             tf.math.subtract(m2_helper(probability_matrix), \n",
    "                                               tf.math.pow(m_helper(probability_matrix), 2)), \n",
    "                             tf.math.pow(m_helper(probability_matrix), 2)), \n",
    "                         probability_matrices)\n",
    "    \n",
    "    def average_cluster_percolation(self, binary_inputs, kernel_size):\n",
    "        number_of_ones = tf.map_fn(lambda binary_input: tf.map_fn(lambda binary_patch: tf.math.reduce_sum(binary_patch), \n",
    "                                                                  binary_input), \n",
    "                                   binary_inputs)\n",
    "        _, patch_number = number_of_ones.shape\n",
    "        \n",
    "        return tf.math.divide(\n",
    "                    tf.math.reduce_sum(\n",
    "                        tf.cast(\n",
    "                            tf.math.greater_equal(\n",
    "                                tf.math.divide(number_of_ones, kernel_size ** 2), \n",
    "                                self.PERCOLATION_THRESHOLD), \n",
    "                            dtype=tf.int32), \n",
    "                    axis=1),\n",
    "                patch_number)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        kernel_size_start, kernel_size_end = self.kernel_size_range\n",
    "        \n",
    "        for kernel_size in range(kernel_size_start, kernel_size_end + 1, 2):\n",
    "            cd_binary_patches = self.extract_binary_patches(inputs, kernel_size, distance_function=self.chessboard_distance)\n",
    "            cd_probability_matrices = self.calculate_probability_matrices(cd_binary_patches, kernel_size)\n",
    "            cd_fractal_dimensions = self.calculate_fractal_dimensions(cd_probability_matrices)\n",
    "            cd_lacunarity = self.calculate_lacunarity(cd_probability_matrices)\n",
    "            print(f'lacunarity shape: {cd_lacunarity.shape}')\n",
    "            self.average_cluster_number(cd_binary_patches)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ładujemy dane do trenowania i walidacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 640 images belonging to 3 classes.\n",
      "Found 159 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(validation_split=0.2, rescale=1.0)\n",
    "training_set = datagen.flow_from_directory('/small-data',\n",
    "                                           target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           class_mode='categorical',\n",
    "                                           subset='training')\n",
    "validation_set = datagen.flow_from_directory('/small-data',\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             class_mode='categorical',\n",
    "                                             subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Zapisujemy ilość rozpoznawalnych diagnoz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DIAGNOSIS_NUMBER = len(training_set.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Tworzymy model, który wykorzystuje wcześniej zdefiniowaną warstwę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lacunarity shape: (None,)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Exception encountered when calling layer \"fractal2d\" (type Fractal2D).\n\nin user code:\n\n    File \"<ipython-input-4-0af4dd71a20f>\", line 92, in call  *\n        self.average_cluster_number(cd_binary_patches)\n    File \"<ipython-input-4-0af4dd71a20f>\", line 80, in average_cluster_number  *\n        _, cluster_number =  measurements.label(binary_inputs[0])\n    File \"/usr/local/lib/python3.8/dist-packages/scipy/ndimage/measurements.py\", line 176, in label  *\n        input = numpy.asarray(input)\n\n    NotImplementedError: Cannot convert a symbolic Tensor (fractal2d/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 224, 224, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-815fe060eab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = tf.keras.Sequential([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mFractal2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m41\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", \n\u001b[1;32m      5\u001b[0m                    \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1280\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Exception encountered when calling layer \"fractal2d\" (type Fractal2D).\n\nin user code:\n\n    File \"<ipython-input-4-0af4dd71a20f>\", line 92, in call  *\n        self.average_cluster_number(cd_binary_patches)\n    File \"<ipython-input-4-0af4dd71a20f>\", line 80, in average_cluster_number  *\n        _, cluster_number =  measurements.label(binary_inputs[0])\n    File \"/usr/local/lib/python3.8/dist-packages/scipy/ndimage/measurements.py\", line 176, in label  *\n        input = numpy.asarray(input)\n\n    NotImplementedError: Cannot convert a symbolic Tensor (fractal2d/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 224, 224, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "    Fractal2D(kernel_size_range=(3, 41)),\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", \n",
    "                   output_shape=[1280],\n",
    "                   trainable=False),\n",
    "    tf.keras.layers.Dense(DIAGNOSIS_NUMBER, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(training_set, validation_data=validation_set, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
